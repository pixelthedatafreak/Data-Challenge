{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:navy\">Alternative 1 : Classifying articles using Convolutional Neural Networks <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the packages we are going to use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesog\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from utils import load_embeddings, preprocessing, get_vocab, add_unknown_words, create_train_test_loaders\n",
    "from model import CNN\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function that returns the number of words from the longest abstract..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_length(abstracts):\n",
    "    max_length = max([len(abstracts[i]) for i in range(0,len(abstracts))])\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function that generates the Train and Test matrices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_matrices(train_abstracts_processed, test_abstracts_processed, vocab, max_length):\n",
    "    X_train = np.zeros((len(train_abstracts_processed),max_length))\n",
    "    X_test = np.zeros((len(test_abstracts_processed),max_length))\n",
    "    for i in range(0,len(train_abstracts_processed)):\n",
    "        for k in range(0,len(train_abstracts_processed[i])):\n",
    "            X_train[i][k] = vocab[train_abstracts_processed[i][k]]\n",
    "    for i in range(0,len(test_abstracts_processed)):\n",
    "        for k in range(0,len(test_abstracts_processed[i])):\n",
    "            X_test[i][k] = vocab[test_abstracts_processed[i][k]]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading data about each article in a dataframe ( id/year/title/authors/abstract ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  year                                              title  \\\n",
      "0  1001  2000              compactification geometry and duality   \n",
      "1  1002  2000  domain walls and massive gauged supergravity p...   \n",
      "2  1003  2000     comment on metric fluctuations in brane worlds   \n",
      "3  1004  2000         moving mirrors and thermodynamic paradoxes   \n",
      "4  1005  2000  bundles of chiral blocks and boundary conditio...   \n",
      "\n",
      "                       authors  \\\n",
      "0            Paul S. Aspinwall   \n",
      "1  M. Cvetic, H. Lu, C.N. Pope   \n",
      "2     Y.S. Myung, Gungwon Kang   \n",
      "3               Adam D. Helfer   \n",
      "4      J. Fuchs, C. Schweigert   \n",
      "\n",
      "                                            abstract  \n",
      "0  these are notes based on lectures given at tas...  \n",
      "1  we point out that massive gauged supergravity ...  \n",
      "2  recently ivanov and volovich hep-th 9912242 cl...  \n",
      "3  quantum fields responding to moving mirrors ha...  \n",
      "4  proceedings of lie iii clausthal july 1999 var...  \n"
     ]
    }
   ],
   "source": [
    "# Load data about each article in a dataframe\n",
    "df = pd.read_csv(\"node_information.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading data (document ids and the corresponding journal they were published in).**\n",
    "\n",
    "\n",
    "### ** We have 28 journals **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "train_ids = list()\n",
    "class_labels = list()\n",
    "with open('train.csv', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        train_ids.append(t[0])\n",
    "        class_labels.append(t[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of classes:  28\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_ids)\n",
    "unique = np.unique(class_labels)\n",
    "print(\"\\nNumber of classes: \", unique.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Indexing the unique classes in order to use them as Y in Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_to_idx = dict()\n",
    "for i in range(unique.size):\n",
    "    class_label_to_idx[unique[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acta': 0,\n",
       " 'Adv.Theor.Math.Phys.': 1,\n",
       " 'Annals': 2,\n",
       " 'Class.Quant.Grav.': 3,\n",
       " 'Commun.Math.Phys.': 4,\n",
       " 'Eur.Phys.J.': 5,\n",
       " 'Fortsch.Phys.': 6,\n",
       " 'Int.': 7,\n",
       " 'Int.J.Mod.Phys.': 8,\n",
       " 'Int.J.Theor.Phys.': 9,\n",
       " 'J.Geom.Phys.': 10,\n",
       " 'J.Math.Phys.': 11,\n",
       " 'J.Phys.': 12,\n",
       " 'JHEP': 13,\n",
       " 'Lett.Math.Phys.': 14,\n",
       " 'Mod.': 15,\n",
       " 'Mod.Phys.Lett.': 16,\n",
       " 'Nucl.': 17,\n",
       " 'Nucl.Phys.': 18,\n",
       " 'Nucl.Phys.Proc.Suppl.': 19,\n",
       " 'Nuovo': 20,\n",
       " 'Phys.': 21,\n",
       " 'Phys.Lett.': 22,\n",
       " 'Phys.Rev.': 23,\n",
       " 'Phys.Rev.Lett.': 24,\n",
       " 'Prog.Theor.Phys.': 25,\n",
       " 'Theor.Math.Phys.': 26,\n",
       " 'Z.Phys.': 27}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_label_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building y_train matrix by vectorizing which article belongs to which class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.zeros((n_train, unique.size), dtype=np.int64)\n",
    "for i in range(n_train):\n",
    "    y_train[i,class_label_to_idx[class_labels[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting abstracts for training and validation ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the abstract of each training article from the dataframe\n",
    "train_abstracts = list()\n",
    "for i in train_ids:\n",
    "    train_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0]+\" \"+str(df.loc[df['id'] == int(i)]['title'].iloc[0])+ \" \"+str(df.loc[df['id'] == int(i)]['authors'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading test ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "test_ids = list()\n",
    "with open('test.csv', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        test_ids.append(line[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting the abstracts that correspond to the test ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(test_ids)\n",
    "test_abstracts = list()\n",
    "for i in test_ids:\n",
    "    test_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0]+\" \"+str(df.loc[df['id'] == int(i)]['title'].iloc[0])+ \" \"+str(df.loc[df['id'] == int(i)]['authors'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cleaning the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstracts_processed = preprocessing(train_abstracts)\n",
    "test_abstracts_processed = preprocessing(test_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Combining abstracts of both train and test ids  in a list in order to extract info.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = list()\n",
    "abstracts.extend(train_abstracts_processed)\n",
    "abstracts.extend(test_abstracts_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collecting the unique words of the abstracts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 28946\n"
     ]
    }
   ],
   "source": [
    "# Extract vocabulary\n",
    "vocab = get_vocab(abstracts)\n",
    "print('Vocab size:', len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating word embeddings from every word in the vocabulary either it exists or not**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing vecs: 18101\n"
     ]
    }
   ],
   "source": [
    "embeddings, unknown_words = load_embeddings('GoogleNews-vectors-negative300.bin.gz', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_unknown_words(embeddings, vocab, unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = compute_max_length(abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the training and test matrices.**\n",
    "- Each row corresponds to an article and each column to a word present in every single article. \n",
    "- An element corresponds to the index of a vocabulary word that is present in the article. For example element [i][j] is the index that corresponds to the jth word of article i's abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = create_train_test_matrices(train_abstracts_processed, test_abstracts_processed, vocab, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating CNN model and feeding it with the training matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loader, test_loader = create_train_test_loaders(X_train, X_test, y_train, batch_size)\n",
    "           \n",
    "cnn = CNN(max_length, len(vocab)+1, y_train.shape[1], [2,3], [100,100], embeddings)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    " \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, cnn.parameters()), lr=learning_rate)\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (abstracts, labels) in enumerate(train_loader):\n",
    "        abstracts = Variable(abstracts)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs,_ = cnn(abstracts)\n",
    "        loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  #  print(\"epoch: \"+str(epoch+1)+\"   loss: \"+str(loss.data.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Predicting the classes of test article ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = np.zeros((n_test, y_train.shape[1]))\n",
    "cnn.eval() \n",
    "for i, (abstract,_) in enumerate(test_loader):\n",
    "    abstracts = Variable(abstract)\n",
    "    _,outputs = cnn(abstract)\n",
    "    y_pred[i,:] = outputs.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Writing results to csv file in order to evaluate the model in Kaggle**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to a file\n",
    "with open('text_cnn.csv', 'w')as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    lst = unique.tolist()\n",
    "    lst.insert(0, \"Article\")\n",
    "    writer.writerow(lst)\n",
    "    for i,test_id in enumerate(test_ids):\n",
    "        lst = y_pred[i,:].tolist()\n",
    "        lst.insert(0, test_id)\n",
    "        writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:navy\"> Kaggle evaluation : 1.99424 <span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
