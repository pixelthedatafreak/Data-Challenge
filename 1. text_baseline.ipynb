{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:navy\">Alternative 1 : Classifying articles using their abstracts <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the packages we are going to use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading data about each article in a dataframe ( id/year/title/authors/abstract ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'year', 'title', 'authors', 'abstract'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"node_information.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading data (document ids and the corresponding journal they were published in).**\n",
    "\n",
    "\n",
    "### ** We have 28 journals **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of classes:  28\n"
     ]
    }
   ],
   "source": [
    "all_ids = list()\n",
    "y_all = list()\n",
    "with open('train.csv', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        t = line.split(',')\n",
    "        all_ids.append(t[0])\n",
    "        y_all.append(t[1][:-1])\n",
    "n_all = len(all_ids)\n",
    "unique = np.unique(y_all)\n",
    "print(\"\\nNumber of classes: \", unique.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting in train and validation set in order to run my own evaluation before uploading the results on kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids,valid_ids, y_train, y_val = train_test_split(all_ids, y_all, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents used for training :  12272\n",
      "Number of documents used for validation:  3069\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents used for training : \",len(train_ids))\n",
    "print(\"Number of documents used for validation: \",len(valid_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting abstracts for training and validation ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstracts = list()\n",
    "val_abstracts = list()\n",
    "\n",
    "for i in train_ids:\n",
    "    train_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0])\n",
    "\n",
    "for i in valid_ids:\n",
    "    val_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train abstracts dimensionality:  12272\n",
      "Validation abstracts dimensionality:  3069\n"
     ]
    }
   ],
   "source": [
    "print(\"Train abstracts dimensionality: \", len(train_abstracts))\n",
    "print(\"Validation abstracts dimensionality: \", len(val_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the training matrix and validation matrix.**\n",
    "- Each row corresponds to an article and each column to a word present in at least 2 and at most 50 articles. \n",
    "- The value of each entry in a row is equal to the frequency of that word in the corresponding article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(decode_error='ignore', min_df=2, max_df=50, stop_words='english')\n",
    "X_train = vec.fit_transform(train_abstracts)\n",
    "X_valid = vec.transform(val_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix dimensionality:  (12272, 7965)\n",
      "Validation matrix dimensionality:  (3069, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train matrix dimensionality: \", X_train.shape)\n",
    "print(\"Validation matrix dimensionality: \", X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading data (document ids and the corresponding journal they were published in).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = list()\n",
    "with open('test.csv', 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        test_ids.append(line[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracting abstracts for test ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the abstract of each test article from the dataframe\n",
    "n_test = len(test_ids)\n",
    "test_abstracts = list()\n",
    "for i in test_ids:\n",
    "    test_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the test matrix **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the test matrix following the same approach as in the case of the training matrix\n",
    "X_test = vec.transform(test_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix dimensionality:  (12272, 7965)\n",
      "Validation matrix dimensionality:  (3069, 7965)\n",
      "Test matrix dimensionality:  (3836, 7965)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train matrix dimensionality: \", X_train.shape)\n",
    "print(\"Validation matrix dimensionality: \", X_valid.shape)\n",
    "print(\"Test matrix dimensionality: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic regression classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifiers's los :  2.53412567057\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"Logistic Regression classifiers's los : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SGD classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesog\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP classifier's loss :  2.57648476773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"SGD classifier's loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVC classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC classifier's loss :  2.39967155118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(random_state=0,probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"SVC classifier's loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " | **Logistic Regression**        | **SGD**           | **SVC**  |\n",
    " | :-------------: |:-------------:| :-----: |\n",
    " | 2.53412567057      | 2.57648476773 | **2.39967155118** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:DarkGreen\"> We notice that SVC  has the best performance out of the previous classifiers.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:navy\">Alternative 2 : Classifying articles using all their text info. <span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding year, title and authors in our training  and validation data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_years = list()\n",
    "train_titles = list()\n",
    "train_authors = list()\n",
    "\n",
    "val_years = list()\n",
    "val_titles = list()\n",
    "val_authors = list()\n",
    "\n",
    "for i in train_ids:\n",
    "    train_years.append(df.loc[df['id'] == int(i)]['year'].iloc[0])\n",
    "    train_titles.append(df.loc[df['id'] == int(i)]['title'].iloc[0])\n",
    "    if type(df.loc[df['id'] == int(i)]['authors'].iloc[0]) != float:\n",
    "        train_authors.append(df.loc[df['id'] == int(i)]['authors'].iloc[0])\n",
    "    else:\n",
    "        train_authors.append(\"\")\n",
    "\n",
    "for i in valid_ids:\n",
    "    val_years.append(df.loc[df['id'] == int(i)]['year'].iloc[0])\n",
    "    val_titles.append(df.loc[df['id'] == int(i)]['title'].iloc[0])\n",
    "    if type(df.loc[df['id'] == int(i)]['authors'].iloc[0]) != float:\n",
    "        val_authors.append(df.loc[df['id'] == int(i)]['authors'].iloc[0])\n",
    "    else:\n",
    "        val_authors.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = list()\n",
    "for i in range(0,len(train_abstracts)):\n",
    "    train_all.append(train_abstracts[i] + \" \" + train_titles[i] + \" \" + str(train_years[i]) + \" \" + str(train_authors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_all = list()\n",
    "for i in range(0,len(val_abstracts)):\n",
    "    valid_all.append(val_abstracts[i] + \" \" + val_titles[i] + \" \" + str(val_years[i]) + \" \" + str(val_authors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the new training and validation matrices.**\n",
    "- Each row corresponds to an article and each column to a word present in at least 2 and at most 50 articles. \n",
    "- The value of each entry in a row is equal to the frequency of that word in the corresponding article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(decode_error='ignore', min_df=2, max_df=50, stop_words='english')\n",
    "X_train = vec.fit_transform(train_all)\n",
    "X_valid = vec.transform(valid_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reconstructing test data in order to include the new info **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abstracts = list()\n",
    "for i in test_ids:\n",
    "    test_abstracts.append(df.loc[df['id'] == int(i)]['abstract'].iloc[0])\n",
    "    \n",
    "test_years = list()\n",
    "test_titles = list()\n",
    "test_authors = list()\n",
    "\n",
    "for i in test_ids:\n",
    "    test_years.append(df.loc[df['id'] == int(i)]['year'].iloc[0])\n",
    "    test_titles.append(df.loc[df['id'] == int(i)]['title'].iloc[0])\n",
    "    if type(df.loc[df['id'] == int(i)]['authors'].iloc[0]) != float:\n",
    "        test_authors.append(df.loc[df['id'] == int(i)]['authors'].iloc[0])\n",
    "    else:\n",
    "        test_authors.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = list()\n",
    "for i in range(0,len(test_abstracts)):\n",
    "    test_all.append(test_abstracts[i] + \" \" + test_titles[i] + \" \" + str(test_years[i]) + \" \" + str(test_authors[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Creating new test matrix **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vec.transform(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix dimensionality:  (12272, 12011)\n",
      "Validation matrix dimensionality:  (3069, 12011)\n",
      "Test matrix dimensionality:  (3836, 12011)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train matrix dimensionality: \", X_train.shape)\n",
    "print(\"Validation matrix dimensionality: \", X_valid.shape)\n",
    "print(\"Test matrix dimensionality: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic regression classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifiers's los :  2.41165919834\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"Logistic Regression classifiers's los : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SGD classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesog\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD classifier's loss :  2.48548767875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"SGD classifier's loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVC classifier to classify the articles of the validation set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC classifier's loss :  2.30822787892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(random_state=0,probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_valid)\n",
    "loss = log_loss(y_val,y_pred)\n",
    "print(\"SVC classifier's loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " | **Logistic Regression**        | **SGD**           | **SVC**  |\n",
    " | :-------------: |:-------------:| :-----: |\n",
    " | 2.41165919834      | 2.48548767875 | **2.30822787892** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:DarkGreen\"> SVC has still the best performance out of the previous classifiers.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We are using SVC in order to classify our test data and create the according .csv file for Kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to a file\n",
    "with open('text_baseline_results.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    lst = clf.classes_.tolist()\n",
    "    lst.insert(0, \"Article\")\n",
    "    writer.writerow(lst)\n",
    "    for i,test_id in enumerate(test_ids):\n",
    "        lst = y_pred[i,:].tolist()\n",
    "        lst.insert(0, test_id)\n",
    "        writer.writerow(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:navy\"> Kaggle evaluation : 2.25878 <span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
